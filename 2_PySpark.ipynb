{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_PySpark",
      "provenance": [],
      "collapsed_sections": [
        "wox7CNOGJGrF",
        "QVW92KejMHoY",
        "E7EKwiUaOZ7N",
        "7LXuTmOsNdyp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarianaDuartee/ProjetoFinal/blob/main/2_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wox7CNOGJGrF"
      },
      "source": [
        "### INSTALANDO DEPENDECIAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG4awT5LJEmS"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install gcsfs\n",
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVW92KejMHoY"
      },
      "source": [
        "### IMPORTANDO DATAFRAMES, BIBLIOTECAS, ABRINDO SPARKSESSION E CONFIGURANDO CHAVE DE SERVIÇO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA3IQkKCL2sI"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SQLContext\n",
        "from google.cloud import storage\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import DateType\n",
        "\n",
        "import pyspark\n",
        "import pyspark.sql.functions as F\n",
        "import os\n",
        "import gcsfs\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO9olZPDMpxb"
      },
      "source": [
        "spark = SparkSession.builder\\\n",
        ".master('local')\\\n",
        ".appName('Projeto_Final')\\\n",
        ".config('spark.ui.enable', 'true')\\\n",
        ".config('spark.ui.port', '4050')\\\n",
        ".getOrCreate()\n",
        "\n",
        "spark\n",
        "\n",
        "serviceaccount = '/content/soulcode-projeto-final-4b88bea6e07a.json'\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = serviceaccount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7EKwiUaOZ7N"
      },
      "source": [
        "### EXTRAINDO INFORMAÇÕES E ANALISANDO DATAFRAMES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjEFDl68OhtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc12bf80-4588-4cdc-b730-f3d9f476d8f5"
      },
      "source": [
        "'''https://acervolima.com/como-converter-pandas-para-pyspark-dataframe/'''\n",
        "\n",
        "# ARQUIVO 1\n",
        "file_path_1 = 'gs://data_lake_ingest_data/2_temp/temp_pandas_despesas_normalizado.csv'\n",
        "\n",
        "fs = gcsfs.GCSFileSystem(project='soulcode-projeto-final', token=serviceaccount)\n",
        "with fs.open(file_path_1):\n",
        "    data = pd.read_csv(file_path_1, sep=',', encoding='UTF-8', header=0)\n",
        "\n",
        "df_1 = spark.createDataFrame(data)\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "#ARQUIVO 2\n",
        "file_path_2 = 'gs://data_lake_ingest_data/2_temp/temp_pandas_ocorrencias_normalizado.json'\n",
        "\n",
        "fs = gcsfs.GCSFileSystem(project='soulcode-projeto-final', token=serviceaccount)\n",
        "with fs.open(file_path_2):\n",
        "    data = pd.read_json(file_path_2, encoding='UTF-8')\n",
        "\n",
        "df_2 = spark.createDataFrame(data)\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "#ARQUIVO 3\n",
        "file_path_3 = 'gs://data_lake_ingest_data/2_temp/temp_pandas_vitimas_normalizado.json'\n",
        "\n",
        "fs = gcsfs.GCSFileSystem(project='soulcode-projeto-final', token=serviceaccount)\n",
        "with fs.open(file_path_3):\n",
        "    data = pd.read_json(file_path_3, encoding='UTF-8')\n",
        "\n",
        "df_3 = spark.createDataFrame(data)\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "#ARQUIVO 4\n",
        "file_path_4 = 'gs://data_lake_ingest_data/2_temp/temp_pandas_ocorrencias_normalizado.json'\n",
        "\n",
        "fs = gcsfs.GCSFileSystem(project='soulcode-projeto-final', token=serviceaccount)\n",
        "with fs.open(file_path_4):\n",
        "    data = pd.read_json(file_path_4, encoding='UTF-8')\n",
        "\n",
        "df_4 = spark.createDataFrame(data)\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "#ARQUIVO 5\n",
        "file_path_5 = 'gs://data_lake_ingest_data/2_temp/temp_pandas_ocorrencia_vitimas_porAnoEstado.csv'\n",
        "\n",
        "fs = gcsfs.GCSFileSystem(project='soulcode-projeto-final', token=serviceaccount)\n",
        "with fs.open(file_path_5):\n",
        "    data = pd.read_csv(file_path_5, sep=',', encoding='UTF-8')\n",
        "\n",
        "df_5 = spark.createDataFrame(data)\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "# ARQUIVO 6\n",
        "file_path_6 = 'gs://data_lake_ingest_data/1_input/Tabela_frequencia_escolar.xlsx'\n",
        "\n",
        "fs = gcsfs.GCSFileSystem(project='soulcode-projeto-final', token=serviceaccount)\n",
        "with fs.open(file_path_6):\n",
        "    data = pd.read_excel(file_path_6, header=0)\n",
        "\n",
        "df_6 = spark.createDataFrame(data)\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "# ARQUIVO 7\n",
        "file_path_7 = 'gs://data_lake_ingest_data/2_temp/temp_pandas_taxa_analfabetismo_normalizado.csv'\n",
        "\n",
        "fs = gcsfs.GCSFileSystem(project='soulcode-projeto-final', token=serviceaccount)\n",
        "with fs.open(file_path_7):\n",
        "    data = pd.read_csv(file_path_7, header=0)\n",
        "\n",
        "df_7 = spark.createDataFrame(data)\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "df_1.printSchema()\n",
        "df_1.show(5, truncate=False)\n",
        "df_1.dtypes\n",
        "\n",
        "df_2.printSchema()\n",
        "df_2.show(5, truncate=False)\n",
        "df_2.dtypes\n",
        "\n",
        "df_3.printSchema()\n",
        "df_3.show(5, truncate=False)\n",
        "df_3.dtypes\n",
        "\n",
        "df_4.printSchema()\n",
        "df_4.show(5, truncate=False)\n",
        "df_4.dtypes\n",
        "\n",
        "df_5.printSchema()\n",
        "df_5.show(5, truncate=False)\n",
        "df_5.dtypes\n",
        "\n",
        "df_6.printSchema()\n",
        "df_6.show(5, truncate=False)\n",
        "df_6.dtypes\n",
        "\n",
        "df_7.printSchema()\n",
        "df_7.show(5, truncate=False)\n",
        "df_7.dtypes"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- UF: string (nullable = true)\n",
            " |-- Despesas2016: double (nullable = true)\n",
            " |-- Despesas2017: double (nullable = true)\n",
            " |-- Despesas2018: double (nullable = true)\n",
            " |-- Despesas2019: double (nullable = true)\n",
            " |-- Despesas2020: double (nullable = true)\n",
            " |-- Variacao%: double (nullable = true)\n",
            " |-- Previsao2021|Media: double (nullable = true)\n",
            "\n",
            "+--------+------------------+------------+------------------+------------+------------------+---------+------------------+\n",
            "|UF      |Despesas2016      |Despesas2017|Despesas2018      |Despesas2019|Despesas2020      |Variacao%|Previsao2021|Media|\n",
            "+--------+------------------+------------+------------------+------------+------------------+---------+------------------+\n",
            "|Acre    |498.535           |568.361     |627.351           |692.57      |493.75300000000004|8.5      |576.114           |\n",
            "|Amapá   |475.32300000000004|500.227     |489.228           |606.366     |752.252           |52.3     |564.6792          |\n",
            "|Amazonas|1604.7320000000002|1578.957    |1862.6689999999999|2108.46     |2101.447          |60.4     |1851.253          |\n",
            "|Pará    |2551.741          |2579.916    |2903.2            |2943.448    |2966.553          |58.0     |2788.9716         |\n",
            "|Rondônia|874.8739999999999 |895.868     |903.2539999999999 |853.971     |999.044           |-14.7    |905.4022          |\n",
            "+--------+------------------+------------+------------------+------------+------------------+---------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- UF: string (nullable = true)\n",
            " |-- TipoCrime: string (nullable = true)\n",
            " |-- Ano: long (nullable = true)\n",
            " |-- Mes: string (nullable = true)\n",
            " |-- Ocorrencias: long (nullable = true)\n",
            "\n",
            "+----+-------------------------------+----+-------+-----------+\n",
            "|UF  |TipoCrime                      |Ano |Mes    |Ocorrencias|\n",
            "+----+-------------------------------+----+-------+-----------+\n",
            "|Acre|Estupro                        |2021|janeiro|39         |\n",
            "|Acre|Furto de veículo               |2021|janeiro|55         |\n",
            "|Acre|Homicídio doloso               |2021|janeiro|14         |\n",
            "|Acre|Lesão corporal seguida de morte|2021|janeiro|0          |\n",
            "|Acre|Roubo a instituição financeira |2021|janeiro|0          |\n",
            "+----+-------------------------------+----+-------+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- UF: string (nullable = true)\n",
            " |-- TipoCrime: string (nullable = true)\n",
            " |-- Ano: long (nullable = true)\n",
            " |-- Mes: string (nullable = true)\n",
            " |-- SexoVitima: string (nullable = true)\n",
            " |-- Vitimas: long (nullable = true)\n",
            "\n",
            "+----+----------------+----+---------+----------+-------+\n",
            "|UF  |TipoCrime       |Ano |Mes      |SexoVitima|Vitimas|\n",
            "+----+----------------+----+---------+----------+-------+\n",
            "|Acre|Homicídio doloso|2021|janeiro  |Feminino  |1      |\n",
            "|Acre|Homicídio doloso|2021|janeiro  |Masculino |13     |\n",
            "|Acre|Homicídio doloso|2021|janeiro  |Sexo NI   |0      |\n",
            "|Acre|Homicídio doloso|2021|fevereiro|Feminino  |4      |\n",
            "|Acre|Homicídio doloso|2021|fevereiro|Masculino |12     |\n",
            "+----+----------------+----+---------+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- UF: string (nullable = true)\n",
            " |-- TipoCrime: string (nullable = true)\n",
            " |-- Ano: long (nullable = true)\n",
            " |-- Mes: string (nullable = true)\n",
            " |-- Ocorrencias: long (nullable = true)\n",
            "\n",
            "+----+-------------------------------+----+-------+-----------+\n",
            "|UF  |TipoCrime                      |Ano |Mes    |Ocorrencias|\n",
            "+----+-------------------------------+----+-------+-----------+\n",
            "|Acre|Estupro                        |2021|janeiro|39         |\n",
            "|Acre|Furto de veículo               |2021|janeiro|55         |\n",
            "|Acre|Homicídio doloso               |2021|janeiro|14         |\n",
            "|Acre|Lesão corporal seguida de morte|2021|janeiro|0          |\n",
            "|Acre|Roubo a instituição financeira |2021|janeiro|0          |\n",
            "+----+-------------------------------+----+-------+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- UF: string (nullable = true)\n",
            " |-- Ano: long (nullable = true)\n",
            " |-- TipoCrime: string (nullable = true)\n",
            " |-- Ocorrencias: long (nullable = true)\n",
            " |-- Vitimas: long (nullable = true)\n",
            "\n",
            "+----+----+-----------------------------------+-----------+-------+\n",
            "|UF  |Ano |TipoCrime                          |Ocorrencias|Vitimas|\n",
            "+----+----+-----------------------------------+-----------+-------+\n",
            "|Acre|2016|Homicídio doloso                   |425        |354    |\n",
            "|Acre|2017|Homicídio doloso                   |221        |232    |\n",
            "|Acre|2017|Lesão corporal seguida de morte    |0          |3      |\n",
            "|Acre|2017|Roubo seguido de morte (latrocínio)|10         |15     |\n",
            "|Acre|2018|Homicídio doloso                   |396        |394    |\n",
            "+----+----+-----------------------------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- Grandes Regiões, Unidades da Federação e Municípios das Capitais: string (nullable = true)\n",
            " |-- 15 a 17 anos - 2019: double (nullable = true)\n",
            " |-- 15 a 17 anos - 2018: double (nullable = true)\n",
            " |-- 15 a 17 anos - 2017: double (nullable = true)\n",
            " |-- 15 a 17 anos - 2016: double (nullable = true)\n",
            " |-- Media 15 a 17 anos: double (nullable = true)\n",
            " |-- 18 a 24 anos - 2019: double (nullable = true)\n",
            " |-- 18 a 24 anos - 2018: double (nullable = true)\n",
            " |-- 18 a 24 anos - 2017: double (nullable = true)\n",
            " |-- 18 a 24 anos - 2016: double (nullable = true)\n",
            " |-- média 18 a 24 anos: double (nullable = true)\n",
            " |-- 25 anos ou mais - 2019: double (nullable = true)\n",
            " |-- 25 anos ou mais - 2018: double (nullable = true)\n",
            " |-- 25 anos ou mais - 2017: double (nullable = true)\n",
            " |-- 25 anos ou mais - 2016: double (nullable = true)\n",
            " |-- média 25 anos ou mais: double (nullable = true)\n",
            "\n",
            "+----------------------------------------------------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+----------------------+----------------------+----------------------+----------------------+---------------------+\n",
            "|Grandes Regiões, Unidades da Federação e Municípios das Capitais|15 a 17 anos - 2019|15 a 17 anos - 2018|15 a 17 anos - 2017|15 a 17 anos - 2016|Media 15 a 17 anos|18 a 24 anos - 2019|18 a 24 anos - 2018|18 a 24 anos - 2017|18 a 24 anos - 2016|média 18 a 24 anos|25 anos ou mais - 2019|25 anos ou mais - 2018|25 anos ou mais - 2017|25 anos ou mais - 2016|média 25 anos ou mais|\n",
            "+----------------------------------------------------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+----------------------+----------------------+----------------------+----------------------+---------------------+\n",
            "|Brasil                                                          |89.17198948374096  |88.2426144204458   |86.56451335197876  |87.5617260467917   |87.8852108257393  |32.41407932745226  |34.53417795470805  |33.360253247817255 |34.17581270855951  |33.62108080963427 |4.504817075471089     |5.675049480395514     |5.8222092845937174    |6.05481441288333      |5.514222563335913    |\n",
            "|Norte                                                           |88.74982729136596  |87.13363699314166  |86.18634784748102  |86.23343843334908  |87.07581264133444 |33.277336088584065 |30.55755225551167  |31.889367675874244 |31.40075605450034  |31.781253018617576|5.300311202284845     |4.738200441644607     |4.829205200490404     |6.316555051054046     |5.2960679738684755   |\n",
            "|Rondônia                                                        |88.5758890715434   |87.61083310627495  |88.09353317895633  |86.80829519027922  |87.77213763676347 |31.917363776805303 |36.46044648717471  |42.381697360736936 |39.412875441641646 |37.543095766589644|5.696628237780432     |6.806092080969176     |8.094231628524204     |10.102827665601428    |7.67494490321881     |\n",
            "|Porto Velho                                                     |88.95162805125744  |82.5532772565588   |84.18183233290323  |86.43959488451544  |85.53158313130872 |38.26167802729192  |33.024090303693306 |35.08011605454825  |39.44302117520716  |36.45222639018516 |7.482369141571613     |8.496009939035124     |7.956949796455643     |10.15315072431738     |8.52211990034494     |\n",
            "|Acre                                                            |84.98448999182288  |87.17335055657942  |86.65851673769289  |86.68539677641571  |86.37543851562772 |33.834860833327035 |38.86751169841704  |42.36043012159184  |42.89214761645621  |39.488737567448034|6.9339672958134075    |10.321757609195592    |9.98524514543419      |10.493120889846796    |9.433522735072497    |\n",
            "+----------------------------------------------------------------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+-------------------+------------------+----------------------+----------------------+----------------------+----------------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- Unnamed: 0: long (nullable = true)\n",
            " |-- UF: string (nullable = true)\n",
            " |-- Grupo_idade: string (nullable = true)\n",
            " |-- TaxaAnalfabetismo2016: double (nullable = true)\n",
            " |-- TaxaAnalfabetismo2017: double (nullable = true)\n",
            " |-- TaxaAnalfabetismo2018: double (nullable = true)\n",
            " |-- TaxaAnalfabetismo2019: double (nullable = true)\n",
            "\n",
            "+----------+--------+---------------+---------------------+---------------------+---------------------+---------------------+\n",
            "|Unnamed: 0|UF      |Grupo_idade    |TaxaAnalfabetismo2016|TaxaAnalfabetismo2017|TaxaAnalfabetismo2018|TaxaAnalfabetismo2019|\n",
            "+----------+--------+---------------+---------------------+---------------------+---------------------+---------------------+\n",
            "|0         |Rondônia|15 anos ou mais|6.6                  |7.2                  |6.5                  |6.4                  |\n",
            "|1         |Acre    |15 anos ou mais|13.1                 |12.1                 |12.1                 |11.7                 |\n",
            "|2         |Amazonas|15 anos ou mais|6.9                  |6.1                  |5.8                  |5.4                  |\n",
            "|3         |Roraima |15 anos ou mais|6.6                  |6.0                  |6.0                  |5.0                  |\n",
            "|4         |Pará    |15 anos ou mais|9.2                  |8.6                  |8.8                  |8.4                  |\n",
            "+----------+--------+---------------+---------------------+---------------------+---------------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Unnamed: 0', 'bigint'),\n",
              " ('UF', 'string'),\n",
              " ('Grupo_idade', 'string'),\n",
              " ('TaxaAnalfabetismo2016', 'double'),\n",
              " ('TaxaAnalfabetismo2017', 'double'),\n",
              " ('TaxaAnalfabetismo2018', 'double'),\n",
              " ('TaxaAnalfabetismo2019', 'double')]"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsZ927gDOKDx"
      },
      "source": [
        "### NORMALIZANDO DATAFRAMES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAPe60SHVbP6"
      },
      "source": [
        "# DATAFRAME 1\n",
        "df_1 = df_1.drop('Estimativa_2021', 'Previsao2021Media')\n",
        "df_1 = df_1.drop('Estimativa_2021', 'Previsao2021Media')\n",
        "df_1 = df_1.withColumnRenamed('Media Anual', 'Estimativa_Despesa_2021')\n",
        "df_1 = df_1.withColumnRenamed('Previsao2021|Media', 'Previsao2021_Media')\n",
        "\n",
        "df_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE_1C9nSVbZ3"
      },
      "source": [
        "# DATAFRAME 2\n",
        "df_2.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-JOP6bFk4dD"
      },
      "source": [
        "# DATAFRAME 3\n",
        "df_3.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy0-IwUZVhRt"
      },
      "source": [
        "# DATAFRAME 4\n",
        "df_4.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyg9dNdroayn"
      },
      "source": [
        "# DATAFRAME 5\n",
        "df_5.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfQ55azXerU3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2471c2a1-1389-4b11-d792-7285b9dc92a1"
      },
      "source": [
        "# DATAFRAME 6\n",
        "\n",
        "# DROPANDO COLUNAS\n",
        "df_6 = df_6.drop('15 a 17 anos - 2019', \n",
        "                 '15 a 17 anos - 2018',\n",
        "                 '15 a 17 anos - 2017',\n",
        "                 '15 a 17 anos - 2016',\n",
        "                 '18 a 24 anos - 2019',\n",
        "                 '18 a 24 anos - 2018',\n",
        "                 '18 a 24 anos - 2017',\n",
        "                 '18 a 24 anos - 2016',\n",
        "                 '25 anos ou mais - 2019',\n",
        "                 '25 anos ou mais - 2018',\n",
        "                 '25 anos ou mais - 2017',\n",
        "                 '25 anos ou mais - 2016')\n",
        "\n",
        "# RENOMEANDO COLUNAS FAIXA DE IDADE\n",
        "df_6 = df_6.withColumnRenamed('Grandes Regiões, Unidades da Federação e Municípios das Capitais', 'UF')\n",
        "df_6 = df_6.withColumnRenamed('Media 15 a 17 anos', 'Media_Freq_15_a_17_anos')\n",
        "df_6 = df_6.withColumnRenamed('média 18 a 24 anos', 'Media_Freq_18_a_24_anos')\n",
        "df_6 = df_6.withColumnRenamed('média 25 anos ou mais', 'Media_Freq_25_anos_ou_mais')\n",
        "\n",
        "# FILTRO PARA REMOVER REGIÕES E CAPITAIS\n",
        "df_6 = df_6.filter((df_6.UF != \"Brasil\") & \n",
        "            (df_6.UF != \"Norte\") & \n",
        "            (df_6.UF != \"Nordeste\") &\n",
        "            (df_6.UF != \"Sudeste\") & \n",
        "            (df_6.UF != \"Sul\") &\n",
        "            (df_6.UF != \"Centro-Oeste\") &\n",
        "            (df_6.UF != \"Porto Velho\") &\n",
        "            (df_6.UF != \"Rio Branco\") &\n",
        "            (df_6.UF != \"Manaus\") &\n",
        "            (df_6.UF != \"Boa Vista\") &\n",
        "            (df_6.UF != \"Macapá\") &\n",
        "            (df_6.UF != \"Palmas\") &\n",
        "            (df_6.UF != \"São Luiz\") &\n",
        "            (df_6.UF != \"Teresina\") &\n",
        "            (df_6.UF != \"Fortaleza\") &\n",
        "            (df_6.UF != \"Natal\") &\n",
        "            (df_6.UF != \"joão Pessoa\") &\n",
        "            (df_6.UF != \"Recife\") &\n",
        "            (df_6.UF != \"Maceió\") &\n",
        "            (df_6.UF != \"Aracaju\") &\n",
        "            (df_6.UF != \"Salvador\") &\n",
        "            (df_6.UF != \"Belo Horizonte\") &\n",
        "            (df_6.UF != \"Vitória\") &\n",
        "            (df_6.UF != \"Curitiba\") &\n",
        "            (df_6.UF != \"Florianópolis\") &\n",
        "            (df_6.UF != \"Porto Alegre\") &\n",
        "            (df_6.UF != \"Campo Grande\") &\n",
        "            (df_6.UF != \"Cuiabá\") &\n",
        "            (df_6.UF != \"Goiânia\") &\n",
        "            (df_6.UF != \"Brasilia\"))\\\n",
        "            .orderBy('UF', ascending=True)\n",
        "\n",
        "# # INCREMENTANDO TAXA DE EVASÃO\n",
        "# df_6 = df_6.withColumn('Evasao_11_a_14_anos', (df_5.Freq_11_a_14_anos - 100)) \n",
        "# df_6 = df_6.withColumn('Evasao_15_a_17_anos', (df_5.Freq_11_a_14_anos - 100))\n",
        "# df_6 = df_6.withColumn('Evasao_18_a_24_anos', (df_5.Freq_11_a_14_anos - 100))\n",
        "# df_6 = df_6.withColumn('Evasao_25_anos_ou_mais', (df_5.Freq_11_a_14_anos - 100))\n",
        "\n",
        "# CONVERTENDO VALORES EM PORCENTAGEM\n",
        "'''https://stackoverflow.com/questions/60673912/how-to-convert-number-into-percentage'''\n",
        "\n",
        "df_6 = df_6\\\n",
        ".withColumn(\"Media_Freq_15_a_17_anos\", F.concat((F.col(\"Media_Freq_15_a_17_anos\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        ".withColumn(\"Media_Freq_18_a_24_anos\", F.concat((F.col(\"Media_Freq_18_a_24_anos\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        ".withColumn(\"Media_Freq_25_anos_ou_mais\", F.concat((F.col(\"Media_Freq_25_anos_ou_mais\") * 1).cast(\"int\"), F.lit(' %')))\n",
        "# .withColumn(\"Media_Freq_Escolar\", F.concat((F.col(\"Media_Freq_Escolar\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        "# .withColumn(\"Evasao_11_a_14_anos\", F.concat((F.col(\"Evasao_11_a_14_anos\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        "# .withColumn(\"Evasao_15_a_17_anos\", F.concat((F.col(\"Evasao_15_a_17_anos\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        "# .withColumn(\"Evasao_18_a_24_anos\", F.concat((F.col(\"Evasao_18_a_24_anos\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        "# .withColumn(\"Evasao_25_anos_ou_mais\", F.concat((F.col(\"Evasao_25_anos_ou_mais\") * 1).cast(\"int\"), F.lit(' %')))\n",
        "\n",
        "# AJUSTANDO EXIBIÇÃO DO DATAFRAME\n",
        "df_6 = df_6.select('UF', \n",
        "                   'Media_Freq_15_a_17_anos', \n",
        "                #    'Evasao_11_a_14_anos',\n",
        "                   'Media_Freq_18_a_24_anos',\n",
        "                #    'Evasao_15_a_17_anos',\n",
        "                   'Media_Freq_25_anos_ou_mais',\n",
        "                #    'Evasao_18_a_24_anos',\n",
        "                #    'Freq_25_anos_ou_mais',\n",
        "                #    'Evasao_25_anos_ou_mais',\n",
        "                #    'Media_Freq_Escolar'\n",
        "               )\n",
        "\n",
        "'''https://sparkbyexamples.com/pyspark/convert-pyspark-dataframe-to-pandas/'''\n",
        "\n",
        "# TRANSFORMARDO DATAFRAME PYSPAK EM PANDAS\n",
        "# df_join_3 = df_join_3.toPandas()\n",
        "# print(df_join_3)\n",
        "\n",
        "# EXPORTANDO DATAFRAME EM CSV"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://sparkbyexamples.com/pyspark/convert-pyspark-dataframe-to-pandas/'"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU5Gz3ShKsoA"
      },
      "source": [
        "# df_6 = df_6.toPandas()\n",
        "df_6.to_csv('temp_pyspark_tabela_frequencia_escolar_normalizado.csv')\n",
        "\n",
        "BUCKET_NAME= \"data_lake_ingest_data\"\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
        "\n",
        "fileout = \"2_temp/temp_pyspark_tabela_frequencia_escolar_normalizado.csv\"\n",
        "destination_blob = bucket.blob(fileout)\n",
        "destination_blob.upload_from_filename('/content/temp_pyspark_tabela_frequencia_escolar_normalizado.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Flsf5qzGHp"
      },
      "source": [
        "# DATAFRAME 7\n",
        "df_7 = df_7.drop('Grupo_idade')\n",
        "df_7 = df_7.drop('Unnamed: 0')\n",
        "\n",
        "df_7 = df_7\\\n",
        ".withColumn(\"TaxaAnalfabetismo2016\", F.concat((F.col(\"TaxaAnalfabetismo2016\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        ".withColumn(\"TaxaAnalfabetismo2017\", F.concat((F.col(\"TaxaAnalfabetismo2017\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        ".withColumn(\"TaxaAnalfabetismo2018\", F.concat((F.col(\"TaxaAnalfabetismo2018\") * 1).cast(\"int\"), F.lit(' %')))\\\n",
        ".withColumn(\"TaxaAnalfabetismo2019\", F.concat((F.col(\"TaxaAnalfabetismo2019\") * 1).cast(\"int\"), F.lit(' %')))\n",
        "\n",
        "df_7.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE5ise9dksK1"
      },
      "source": [
        "### AGREGANDO DADOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2bgQFezOJDR"
      },
      "source": [
        "# VISUALIZAR DATAFRAMES TRATADOS\n",
        "\n",
        "df_1.show(5, truncate=False)\n",
        "df_2.show(5, truncate=False)\n",
        "df_3.show(5, truncate=False)\n",
        "df_4.show(5, truncate=False)\n",
        "df_5.show(5, truncate=False)\n",
        "df_6.show(5, truncate=False)\n",
        "df_7.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsswAo5erQl-"
      },
      "source": [
        "# AGREGAÇÃO 1\n",
        "\n",
        "#AGRUPANDO VALORES DOS DATAFRAMES\n",
        "df_ins2 = df_2.groupBy('UF').sum('Ocorrencias').orderBy('UF')\n",
        "# df_ins2.show(50, truncate=False)\n",
        "\n",
        "df_ins3 = df_3.groupBy('UF').sum('Vitimas').orderBy('UF')\n",
        "# df_ins3.show(50, truncate=False)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# JOIN 1\n",
        "# AGREGA OS VALORES TOTAIS DE OCORRENCIAS E VITIMAS POR ESTADO \n",
        "\n",
        "df_join_1 = df_ins2.join(df_ins3, on=['UF'], how='inner')\\\n",
        ".select('UF', 'sum(Ocorrencias)', 'sum(Vitimas)')\\\n",
        ".orderBy(F.asc('UF'))\n",
        "\n",
        "# df_join_1.show(50, False)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# JOIN 2\n",
        "# AGREGA OS VALORES TOTAIS DE OCORRENCIAS, VITIMAS, MEDIA DE FREQ. ESCOLAR POR ESTADO \n",
        "\n",
        "df_join_2 = df_join_1.join(df_6, on=['UF'], how='inner')\\\n",
        ".select('UF', 'sum(Ocorrencias)', 'sum(Vitimas)', 'Media_Freq_25_anos_ou_mais')\\\n",
        ".orderBy(F.asc('UF'))\n",
        "\n",
        "# df_join_2.show(50, False)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "# JOIN 3\n",
        "# AGREGA OS VALORES TOTAIS DE DESPESAS GOVERNAMENTAIS, OCORRENCIAS, VITIMAS, MEDIA DE FREQ. ESCOLAR POR ESTADO \n",
        "\n",
        "df_join_3 = df_join_2.join(df_1, on=['UF'], how='inner')\\\n",
        ".select('UF', 'Despesas2020', 'sum(Ocorrencias)', 'sum(Vitimas)', 'Media_Freq_25_anos_ou_mais')\\\n",
        ".orderBy(F.asc('UF'))\n",
        "\n",
        "df_join_3\\\n",
        ".orderBy(\"Despesas2020\", ascending=False)\\\n",
        ".show(50, False)\n",
        "\n",
        "df_join_3.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TofPZBof0Npu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159549dc-1c95-405a-8108-d4f843632760"
      },
      "source": [
        "# AGREGAÇÃO 2\n",
        "\n",
        "# JOIN 1\n",
        "# AGREGA OS VALORES TOTAIS DE OCORRENCIAS E VITIMAS POR ESTADO \n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "df_join_1 = df_6.join(df_7, on=['UF'], how='inner')\\\n",
        ".select('UF', 'Media_Freq_15_a_17_anos', 'Media_Freq_18_a_24_anos', 'Media_Freq_25_anos_ou_mais', \n",
        "        'TaxaAnalfabetismo2016', 'TaxaAnalfabetismo2017', 'TaxaAnalfabetismo2018', 'TaxaAnalfabetismo2019')\\\n",
        ".orderBy(F.asc('UF'))\\\n",
        ".show()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "df_7 = df_7.toPandas()\n",
        "df_7.to_csv('temp_pyspark_taxa_analfave_escolar_normalizado.csv')\n",
        "\n",
        "BUCKET_NAME= \"data_lake_ingest_data\"\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
        "\n",
        "fileout = \"2_temp/temp_pyspark_tabela_frequencia_escolar_normalizado.csv\"\n",
        "destination_blob = bucket.blob(fileout)\n",
        "destination_blob.upload_from_filename('/content/temp_pyspark_tabela_frequencia_escolar_normalizado.csv')"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------------------+-----------------------+--------------------------+---------------------+---------------------+---------------------+---------------------+\n",
            "|                 UF|Media_Freq_15_a_17_anos|Media_Freq_18_a_24_anos|Media_Freq_25_anos_ou_mais|TaxaAnalfabetismo2016|TaxaAnalfabetismo2017|TaxaAnalfabetismo2018|TaxaAnalfabetismo2019|\n",
            "+-------------------+-----------------------+-----------------------+--------------------------+---------------------+---------------------+---------------------+---------------------+\n",
            "|               Acre|                   86 %|                   39 %|                       9 %|                 13 %|                 12 %|                 12 %|                 11 %|\n",
            "|            Alagoas|                   85 %|                   35 %|                       4 %|                 19 %|                 18 %|                 17 %|                 17 %|\n",
            "|              Amapá|                   88 %|                   42 %|                       7 %|                  5 %|                  5 %|                  6 %|                  5 %|\n",
            "|           Amazonas|                   90 %|                   39 %|                       7 %|                  6 %|                  6 %|                  5 %|                  5 %|\n",
            "|              Bahia|                   90 %|                   43 %|                       7 %|                 13 %|                 12 %|                 12 %|                 12 %|\n",
            "|              Ceará|                   88 %|                   33 %|                       5 %|                 15 %|                 14 %|                 13 %|                 13 %|\n",
            "|   Distrito Federal|                   91 %|                   44 %|                       6 %|                  2 %|                  2 %|                  3 %|                  2 %|\n",
            "|     Espírito Santo|                   92 %|                   47 %|                       6 %|                  6 %|                  5 %|                  5 %|                  5 %|\n",
            "|              Goiás|                   87 %|                   39 %|                       5 %|                  6 %|                  5 %|                  5 %|                  5 %|\n",
            "|           Maranhão|                   87 %|                   35 %|                       6 %|                 16 %|                 16 %|                 16 %|                 15 %|\n",
            "|        Mato Grosso|                   90 %|                   39 %|                       7 %|                  6 %|                  6 %|                  7 %|                  6 %|\n",
            "| Mato Grosso do Sul|                   90 %|                   39 %|                       6 %|                  6 %|                  5 %|                  5 %|                  5 %|\n",
            "|       Minas Gerais|                   92 %|                   37 %|                       6 %|                  6 %|                  6 %|                  5 %|                  5 %|\n",
            "|             Paraná|                   87 %|                   41 %|                       5 %|                  4 %|                  4 %|                  5 %|                  4 %|\n",
            "|            Paraíba|                   90 %|                   44 %|                       6 %|                 16 %|                 16 %|                 16 %|                 16 %|\n",
            "|               Pará|                   90 %|                   39 %|                       6 %|                  9 %|                  8 %|                  8 %|                  8 %|\n",
            "|         Pernambuco|                   88 %|                   33 %|                       5 %|                 12 %|                 13 %|                 11 %|                 11 %|\n",
            "|              Piauí|                   94 %|                   42 %|                       6 %|                 17 %|                 16 %|                 16 %|                 16 %|\n",
            "|Rio Grande do Norte|                   92 %|                   41 %|                       5 %|                 14 %|                 13 %|                 12 %|                 13 %|\n",
            "|  Rio Grande do Sul|                   89 %|                   43 %|                       7 %|                  3 %|                  3 %|                  3 %|                  2 %|\n",
            "+-------------------+-----------------------+-----------------------+--------------------------+---------------------+---------------------+---------------------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWfPjmVJkZTR"
      },
      "source": [
        "# AGREGAÇÃO 3\n",
        "\n",
        "#AGRUPANDO VALORES DOS DATAFRAMES\n",
        "df_agg_1 = df_2.filter(df_2.Ano == 2020)\\\n",
        ".groupBy('UF').sum('Ocorrencias').alias('Ocorrencias_2020').orderBy('UF')\n",
        "\n",
        "df_agg_1.show()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "df_agg_2 = df_3.filter(df_3.Ano == 2020)\\\n",
        ".groupBy('UF').sum('Vitimas').alias('Vitimas_2020').orderBy('UF')\n",
        "\n",
        "df_agg_2.show()\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "df_agg_3 = df_1.select('Despesas2020').alias('Despesas_2020')\n",
        "\n",
        "df_agg_3.show()\n",
        "\n",
        "# AGREGA OS VALORES PELO ANO DE 2020\n",
        "\n",
        "df_join_1 = df.join(df_ins3, on=['UF'], how='inner')\\\n",
        ".select('UF', 'sum(Ocorrencias)', 'sum(Vitimas)')\\\n",
        ".orderBy(F.asc('UF'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-SnL3GEesv8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LXuTmOsNdyp"
      },
      "source": [
        "### EXPORTANDO DATAFRAME\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkXLJV27Nc_K"
      },
      "source": [
        "'''https://sparkbyexamples.com/pyspark/convert-pyspark-dataframe-to-pandas/'''\n",
        "\n",
        "# TRANSFORMARDO DATAFRAME PYSPAK EM PANDAS\n",
        "df_join_3 = df_join_3.toPandas()\n",
        "print(df_join_3)\n",
        "\n",
        "# EXPORTANDO DATAFRAME EM CSV\n",
        "df_join_3.to_csv('temp_pyspark_aggregation_1.csv')\n",
        "\n",
        "BUCKET_NAME= \"data_lake_ingest_data\"\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
        "\n",
        "fileout = \"2_temp/temp_pyspark_aggregation_1.csv\"\n",
        "destination_blob = bucket.blob(fileout)\n",
        "destination_blob.upload_from_filename('/content/temp_pyspark_aggregation_1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}