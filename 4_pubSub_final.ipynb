{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_pubSub_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ws_n_2r8v1u-",
        "fYVBdRBLv8Os",
        "KprSvRYxwCs6",
        "JMthvlL0wHyd"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChesterNut999/ProjetoFinal/blob/main/4_pubSub_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws_n_2r8v1u-"
      },
      "source": [
        "### INSTALANDO DEPENDENCIAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2yUfbpxHmMR"
      },
      "source": [
        "!pip install google-cloud-pubsub\n",
        "!pip install fsspec\n",
        "!pip install gcsfs\n",
        "!pip install apache-beam[interactive]\n",
        "!pip install apache_beam[gcp]\n",
        "!pip install google-cloud-bigquery"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYVBdRBLv8Os"
      },
      "source": [
        "### IMPORTANDO BIBLIOTECAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEGAPAFZP8TJ"
      },
      "source": [
        "import csv\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "\n",
        "import fsspec\n",
        "import gcsfs\n",
        "import pandas as pd\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam import window\n",
        "from apache_beam import coders\n",
        "from apache_beam.io.gcp.bigquery import parse_table_schema_from_json\n",
        "from apache_beam.io.gcp.internal.clients import bigquery\n",
        "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.options.pipeline_options import SetupOptions\n",
        "from apache_beam.options.pipeline_options import StandardOptions\n",
        "\n",
        "from google.cloud import pubsub_v1\n",
        "from google.cloud import storage\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Configurando conta de serviço\n",
        "service_account_key = r\"/content/soulcode-projeto-final-4b88bea6e07a.json\"\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KprSvRYxwCs6"
      },
      "source": [
        "### PUB AND SUB (PUBLICANDO E CONSUMINDO DADOS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7GsFGaVR9D_"
      },
      "source": [
        "Produtor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52f8-cY-IeaR"
      },
      "source": [
        "# Setando o tópico de entrada (ingestão)\n",
        "topico = 'projects/soulcode-projeto-final/topics/ingestor_dados'\n",
        "publisher = pubsub_v1.PublisherClient()\n",
        "\n",
        "entrada = r\"/content/2_temp_temp_pandas_total_pop_ano_uf.csv\"\n",
        "\n",
        "# Visualizando entrada dos dados\n",
        "with open(entrada, 'rb') as file:\n",
        "    for row in file:\n",
        "        print('Publicando no topico: ', topico)\n",
        "        publisher.publish(topico,row)\n",
        "        time.sleep(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8vIScqvR-8w"
      },
      "source": [
        "Consumidor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfZBtyqySAzq"
      },
      "source": [
        "# Função de ACK (Aceite)\n",
        "def monstrar_msg(mensagem):\n",
        "  print(('Mensagem: {}'.format(mensagem)))\n",
        "  mensagem.ack()\n",
        "\n",
        "# Setando a subscrição de saída\n",
        "subscription = 'projects/soulcode-projeto-final/subscriptions/consumidor_dados_violencia'\n",
        "subscriber = pubsub_v1.SubscriberClient()\n",
        "\n",
        "subscriber.subscribe(subscription,callback=monstrar_msg)\n",
        "\n",
        "while True:\n",
        "  time.sleep(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8wzeZmeP0WU"
      },
      "source": [
        "# PIPELINE BATCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMthvlL0wHyd"
      },
      "source": [
        "### PIPELINE LOCAL PARA GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5dfP6BR36BD"
      },
      "source": [
        "# Criando pipeline\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "# Modelo de Pipeline. Ingerindo arquivos locais\n",
        "\n",
        "path_file = '/content/1_input_EvolucaoDespesas_FREE.csv'\n",
        "\n",
        "rows = (\n",
        "    p1\n",
        "    |'Extrair_Dados' >> beam.io.ReadFromText(path_file, skip_header_lines=0, coder=coders.BytesCoder())\n",
        "    |'Ler_Elementos' >> beam.Map(lambda element: element)\n",
        "    # |'Separar_Elementos' >> beam.Map(lambda element: element.split(','))\n",
        "    |'Gravar_resultado' >> beam.io.WriteToText('gs://data_lake_ingest_data/1_input/converter/OcorrenciasUF', file_name_suffix='.csv')\n",
        "   )\n",
        "\n",
        "p1.run()\n",
        "\n",
        "df_test = pd.read_csv('gs://data_lake_ingest_data/1_input/converter/OcorrenciasUF-00000-of-00001.csv', sep=',')\n",
        "print(df_test)\n",
        "print(df_test.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tPyPsiwbkm"
      },
      "source": [
        "### GCS PARA BIGQUERY (BATCH)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "UZjFWi3hPqRB",
        "outputId": "86d28d12-a128-42f3-fc6d-22754e26e06c"
      },
      "source": [
        "# CONTINUANDO PIPELINE \n",
        "def print_row(element):\n",
        "    return print(element)\n",
        "    \n",
        "pipeline_args=['--runner=DataflowRunner',\n",
        "               '--job_name=bq-load',\n",
        "               '--project=soulcode-projeto-final',\n",
        "               '--region=southamerica-east1',\n",
        "               '--temp_location=gs://data_lake_ingest_data/temp_process',\n",
        "               '--staging_location=gs://data_lake_ingest_data/temp_process',\n",
        "               '--template_location=gs://data_lake_ingest_data/4_templates/template_model_batch',\n",
        "               '-–save_main_session'\n",
        "               ]\n",
        "\n",
        "options = PipelineOptions(pipeline_args)\n",
        "p1 = beam.Pipeline(options=options)\n",
        "\n",
        "path_file = 'gs://data_lake_ingest_data/2_temp/temp_pandas_total_pop_ano_uf.csv'\n",
        "\n",
        "table_schema = {\n",
        "    \"fields\": [\n",
        "                {\"name\":\"UF\", \"type\":\"STRING\", \"mode\":\"NULLABLE\"},\n",
        "                {\"name\":\"populacao_estimada\", \"type\":\"FLOAT\", \"mode\":\"NULLABLE\"}, \n",
        "                {\"name\":\"Ano\", \"type\":\"INTEGER\", \"mode\":\"NULLABLE\"},\n",
        "            ]\n",
        "        }\n",
        "\n",
        "# https://medium.com/datamindedbe/how-to-build-a-cleaning-pipeline-with-bigquery-and-dataflow-on-gcp-3d2f288d4e1b\n",
        "# https://stackoverflow.com/questions/48741327/writing-nested-schema-to-bigquery-from-dataflow-python\n",
        "# https://stackoverflow.com/questions/53784829/how-to-get-table-schema-from-json-file-parse-table-schema-from-json\n",
        "# https://stackoverflow.com/questions/59217700/dataflow-apache-beam-cant-write-on-bigquery\n",
        "\n",
        "rows = (\n",
        "        p1 \n",
        "        \n",
        "        |'Extraindo_Dados' >> beam.io.ReadFromText(path_file, skip_header_lines=0)\n",
        "        # |'Separar_Elementos' >> beam.Map(lambda element: element.split(','))\n",
        "        |'Print' >> beam.Map(lambda element: print_row(element)).with_output_types(Transaction)\n",
        "        |'Gravar_Resultado' >> beam.io.gcp.bigquery.WriteToBigQuery(\n",
        "                                    table='TesteBeamApache',\n",
        "                                    dataset='Teste',\n",
        "                                    project='soulcode-projeto-final',\n",
        "                                    custom_gcs_temp_location='gs://data_lake_ingest_data/temp_process',\n",
        "                                    schema=table_schema,\n",
        "                                    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
        "                                    create_disposition=bigquery.CreateDisposition.CREATE_IF_NEEDED)\n",
        "        )\n",
        "\n",
        "p1.run().wait_until_finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-–save_main_session=True']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-–save_main_session=True']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'UNKNOWN'"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    }
  ]
}